import gc
import sys
import torch
import random
from datasets import load_dataset
from transformers.models.auto.tokenization_auto import AutoTokenizer
from transformers.models.auto.modeling_auto import AutoModelForCausalLM
from transformers.utils.quantization_config import BitsAndBytesConfig
from utils.data import load_data
from utils.compute import compute_refusals
from utils.apply import apply_abliteration
from utils.arguments import parser, generate_config
from utils.visualize import collect_hidden_states, get_pca_df, scatter_first_two_components

if __name__ == "__main__":
    args = parser.parse_args()
    config = generate_config(args)

    assert (
        isinstance(config["model"], str)
        and isinstance(config["skip-begin"], int)
        and isinstance(config["skip-end"], int)
        and isinstance(config["scale-factor"], float)
        and isinstance(config["layer-fraction"], float)
    )
    if config["skip-begin"] < 1:
        raise ValueError("Do not mess with the first layer!")
    if config["layer-fraction"] < 0.0 or config["layer-fraction"] > 1.0:
        raise ValueError("Invalid layer fraction")

    torch.inference_mode()
    torch.set_grad_enabled(False)

    if config["precision"] == "fp16":
        precision = torch.float16
    elif config["precision"] == "bf16":
        precision = torch.bfloat16
    else:
        precision = torch.float32

    if config["load-in-4bit"]:
        quant_config = BitsAndBytesConfig(
            load_in_4bit=True,
            bnb_4bit_compute_dtype=precision,
            bnb_4bit_use_double_quant=True,
        )
    elif config["load-in-8bit"]:
        quant_config = BitsAndBytesConfig(
            load_in_8bit=True,
            llm_int8_enable_fp32_cpu_offload=True,
            llm_int8_has_fp16_weight=True,
        )
    else:
        quant_config = None

    if isinstance(config["data-harmful"], str):
        harmful_list = load_data(config["data-harmful"])
    else:
        harmful_list = load_data("./data/harmful.parquet")
    if isinstance(config["data-harmless"], str):
        harmless_list = load_data(config["data-harmless"])
    else:
        harmless_list = load_data("./data/harmless.parquet")

    if config["deccp"]:
        deccp_list = load_dataset("augmxnt/deccp", split="censored")
        harmful_list += deccp_list["text"]  # type: ignore

    if isinstance(config["num-harmful"], int) and config["num-harmful"] > 0:
        harmful_list = random.sample(harmful_list, config["num-harmful"])
    if isinstance(config["num-harmless"], int) and config["num-harmless"] > 0:
        harmless_list = random.sample(harmless_list, config["num-harmless"])

    model = AutoModelForCausalLM.from_pretrained(
        config["model"],
        trust_remote_code=True,
        torch_dtype=precision,
        low_cpu_mem_usage=True,
        device_map=config["device"],
        quantization_config=quant_config,
        attn_implementation="flash_attention_2"
        if config["flash-attn"]
        else None,
    )
    model.requires_grad_(False)

    if config["skip-begin"] + config["skip-end"] >= len(model.model.layers):
        raise ValueError("Too many layers to skip.")

    tokenizer = AutoTokenizer.from_pretrained(
        config["model"], trust_remote_code=True, device_map=config["device"]
    )

    if isinstance(config["input-refusal"], str):
        print(f"Loading refusal tensor from {config['input-refusal']}...")
        refusal_dir = torch.load(config["input-refusal"])
    else:
        print("Computing refusal tensor...")
        refusal_dir = compute_refusals(
            model,
            tokenizer,
            harmful_list,
            harmless_list,
            config["layer-fraction"],
        )

    if isinstance(config["output-refusal"], str):
        print(f"Saving refusal tensor to {config['output-refusal']}...")
        torch.save(refusal_dir, config["output-refusal"])

    if not isinstance(config["output"], str):
        sys.exit(0)

    print("Applying refusal tensor...")

    if config["load-in-4bit"] or config["load-in-8bit"]:
        print("Reloading model with bf16 precision...")
        del model
        torch.cuda.empty_cache()
        gc.collect()
        model = AutoModelForCausalLM.from_pretrained(
            config["model"],
            trust_remote_code=True,
            torch_dtype=torch.bfloat16,
            low_cpu_mem_usage=True,
            device_map="cpu",
        )

    if config.get("visualize", False):
        layer_idx = int(config["layer-fraction"] * len(model.model.layers))
        print(f"Visualizing at layer {layer_idx}...")

        harmful_states = collect_hidden_states(
            model, tokenizer, harmful_list, layer_idx
        )
        harmless_states = collect_hidden_states(
            model, tokenizer, harmless_list, layer_idx
        )
        df = get_pca_df(harmful_states=harmful_states, harmless_states=harmless_states, n_components=10)

        scatter_first_two_components(
            df, save_path="pca_scatter_first_two_components.svg"
        )

    model = apply_abliteration(
        model,
        refusal_dir,
        config["skip-begin"],
        config["skip-end"],
        config["scale-factor"],
    )
    print(f"Saving abliterated model to {config['output']}...")
    model.save_pretrained(config["output"])
    tokenizer.save_pretrained(config["output"])
